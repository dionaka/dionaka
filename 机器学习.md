## Q:什么是过拟合，在机器学习中，我们如何应对过拟合问题？
### A:模型过于复杂地学习了训练集中的噪声、异常值或特定模式，导致对新样本的泛化能力下降。
- 数据增强：对原始训练数据进行变换操作（如随机翻转、随机旋转、随机缩放、随机裁剪等）从而扩增训练数据的规模和多样性。
- 正则化：在损失函数中引入正则化项（如L1正则化、L2正则化等），用于限制模型参数的大小，从而减小模型的复杂度。
- 早停策略：在训练过程中，根据验证集的性能表现，在验证集上性能不再提升时提前停止训练。这可以避免模型在训练集上过拟合，通常是在验证集的误差曲线或准确率曲线的拐点处停止训练。
- 随机丢弃：在训练过程中，随机丢弃一些神经元的输出来减少神经元之间的依赖性，强制网络在训练时学习多个独立的子网络。
- 增加训练数据量：减少数据偶然性，如噪声、异常值等。
- 降低模型复杂度：通过减少模型的层数、节点数或卷积核的个数等方式降低模型的复杂度，从而降低过拟合的风险。
- 交叉验证：核心思想是利用有限的数据样本进行多次训练和验证，常见方法：留出法，K折交叉验证，留一法交叉验证，分层K折交叉验证，时间序列交叉验证，自助法交叉验证
- 合适的特征选择：选择对预测目标真正有影响的特征，减少不相关或冗余特征的影响
- 批标准化：在网络的每一层输入进行归一化，可以加速网络的收敛速度，降低模型在训练数据上的过拟合风险。
- 模型集成：通过组合多个不同的模型（如集成学习、模型融合等方式），可以提高模型的泛化能力，减少过拟合的风险。
